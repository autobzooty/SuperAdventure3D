[Pixel][PostProcess]
struct PostNeighborhoodBlend
{
  [BuiltInInput] var ViewportSize : Real2;
  [BuiltInInput] var InverseViewportSize : Real2;
  
  [StageInput] var Uv : Real2;
  
  [Input] var AreaTexture  : Sampler2d;
  [Input] var ColorTexture : Sampler2d;
  
  [Output] var Target0 : Real4;

  function Main()
  {
    var pixelSize = this.InverseViewportSize;
    // Blend Areas from last pass.
    var sampledAreas = this.AreaTexture.Sample(this.Uv);
    // Right, Top, Left, Bottom.
    var areas = Real4(0.0, 0.0, sampledAreas.Z, sampledAreas.X);
    areas.X = this.AreaTexture.Sample(this.Uv + Real2(pixelSize.X, 0.0)).W;
    areas.Y = this.AreaTexture.Sample(this.Uv + Real2(0.0, pixelSize.Y)).Y;
    
    //Pixel has no measureable blend area, no AA required.
    if (Math.Dot(areas, Real4(1.0)) < 0.0000001)
    {
      this.Target0 = this.ColorTexture.Sample(this.Uv);
    }
    else
    {
      // Up to 4 lines can be crossing a pixel (one through each edge). We
      // favor blending by choosing the line with the maximum weight for each
      // direction.
      var blendOffset = Real4(0.0, areas.Y, 0.0, areas.W);
      var blendWeight = areas.YW;
      
      if(Math.Max(areas.X, areas.Z) > Math.Max(areas.Y, areas.W))
      {
        blendWeight = areas.XZ;
        blendOffset = Real4(areas.X, 0.0, areas.Z, 0.0);
      }
      
      // Normalize the blendWeights.
      blendWeight /= Math.Dot(blendWeight, Real2(1.0, 1.0));
      // Pick the left/top or right bottom coordinates to blend with.
      var blendCoords = (blendOffset * Real4(pixelSize.XY, -pixelSize.XY)) + this.Uv.XYXY;
      
      // Finally add the colors, adding both XY and ZW to avoid shader branching.
      var blendedColor = this.ColorTexture.Sample(blendCoords.XY) * blendWeight.X;
      blendedColor += this.ColorTexture.Sample(blendCoords.ZW) * blendWeight.Y;
      
      this.Target0 = blendedColor;
    }
  }
}
